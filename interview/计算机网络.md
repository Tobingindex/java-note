# 计算机网络

> 计算机网络体系结构？

+ 计算机网络体系结构主要有两个标准：OSI参考模型与TCP/IP模型；

+ 两个模型都采用分层的思想，即每层使用下层提供的服务，实现自己的功能和协议，并为上一层提供服务；

【OSI】

+ OSI参考模型将计算机分为七层，分别是：应用层、表示层、会话层、运输层、网络层、数据链路层、网络层。
+ OSI的应用层负责定义应用进程之间的交互规则，表示层主要提供数据压缩，数据加密以及数据描述的功能；会话层负责为两个通信实体之间创建和管理会话；
+ OSI的运输层主要为两个应用进程之间提供服务；
+ 计算机传输数据的链路很多，网络层主要任务是选择合适的网间路由和交换节点；
+ 两台计算机之间传输数据，总是一段一段地进行传送，数据链路层负责将网络层的IP数据包分装成帧，在两个相邻节点之间传送帧；
+ OSI物理层定义了传输接口的物理特征，屏蔽了传输介质的差异，实现计算机节点之间比特流的透明传输；

【TCP/IP】

+ 尽管OSI定义很标准，但是没有考虑到实际的需求，使得该模型很复杂，部分功能冗余；
+ 计算机网络实际标准是TCP/IP协议。
+ TCP/IP协议将计算机网络分为网络分为四层：应用层、运输层、网络互连层、网络访问层。
+ 应用层，对应OSI应用层、表示层、会话层，通过不同应用层协议提供不同的功能；
+ 运输层，对应OSI运输层，为上层应用层应用提供两种主要通信方式，TCP和UDP；
+ 其中TCP面向连接，提供可靠通信，UDP面向无连接，提供快速通信能力；
+ 网络互连层，对应OSI网络层，负责相同或不同网络的计算机之间通信，主要提供两大功能，寻址和分段，将运输层数据分段，并在选择不停的传送线路。
+ 网络接入层，对应OSI的数据链路层，负责监视数据在主机与网络之间的交换。

【两者异同】

+ OSI和TCP/IP都使用了分层模型来简化计算机网络设计，都提供了面向连接和无连接的两种通信方式；
+ OSI采用的是七层模型，对计算机网络划分的更为细致，而TCP/IP采用的是四层协议，且没有对网络层的定义；

【为什么去掉表示层与会话层】

+ 由于表示层与会话层的功能都是应用程序内部实现的，最终产生的是一个应用数据包，而应用程序之间很难实现代码共享，这两部分很难分开，于是在TCP/IP中将这两次划分到应用层中。

【数据在各层之间传输过程】

+ 发送端将应用程序封装好的应用层报文交给运输层；
+ 运输层收到报文添加上运输层首部（源端口、目的端口）交给网络互连层；
+ 网络互连层收到报文，为其添加上IP首部（原地址、目的地址、首部校验、TTL）交给网络接入层；
+ 网络接入层收到IP报文，IP封装成帧（添加上帧头帧尾、透明传输）并进行差错控制（CRC校验，丢弃错误的报文），最终将数据帧放到网络介质上传输。



> IP层的各种协议？

+ IP层主要向上提供鉴定灵活的、无连接的、尽最大努力交付的数据报访问；
+ IP层是TCP/IP体系中最主要的协议之一，与IP协议配套的还有四个协议；
+ ARP协议：地址解析协议，将IP地址转换为硬件地址(MAC地址)，解决同一局域网中主机或路由器IP地址和硬件地址映射问题；
+ RARP协议：逆地址解析协议，将硬件地址转换为IP地址；
+ ICMP协议：网际控制报文协议，报告IP数据报差错信息，包含「差错报告报文」与「询问报文」；
+ IGMP协议：网际组管理协议，主要实现多播功能；



> Ping命令做了什么？基于哪一层？

+ ping用于测试两个主机之间的连通性；
+ ping使用ICMP回送请求与回送回答报文；
+ ping是应用层直接使用网络层ICMP协议，没有通过TCP或UDP。



> 面向无连接和面向连接的服务

+ 运输层分别提供了面向连接的TCP协议和面向无连接的UDP协议。

【UDP】

+ UDP是无连接的，发送数据前不需要建立连接；
+ UDP使用尽最大努力交付，不保证可靠交付，也不使用拥塞控制；
+ UPD面向报文，无拥塞控制，适合多媒体通信需求；
+ UDP支持一对一、一对多、多对一和多对多通信；
+ UDP首部很小，只有8个字节；
+ UDP对应用层交下来的报文，既不合并，也不拆分，直接保留报文边界，交给IP层；
+ UDP对IP层交上来的UDP用户数据报，去除首部之后原封不动交给上层应用进程；

【TCP】

+ TCP是面向连接的运输层协议；
+ 每条TCP有两个端点，每个TCP连接只能是点对点；
+ TCP提供可靠交付服务，提供面向字节流的全双工通信；
+ TCP对应用进程一次把多长的报文发送给TCP缓存并不关系；
+ TCP根据对方给出窗口值和当前网络拥塞程度决定一个报文段包含多少个字节；（与UDP有很大的不同）
+ TCP会把较长的数据划分短一些在再传送。有可能等待积累足够多字节再构成报文段发送出去；
+ TCP连接的端点不是主机，而是套接字Socket。



> 为什么UDP实时性好？

+ 运输层主要有两个主要协议，一个是TCP，另一个就是UDP。
+ TCP为了保证可靠传输，可能会把较长的数据划分短一点，或把较少的积累足够多再构成报文端再发送出去，主要不利用实时性；
+ 而UDP使用时尽最大努力交付，不保证可靠交付，也不使用拥塞控制，报文首部结构简单，占用较少；
+ 同时UDP对于应用层交下来的报文既不合并也不拆分，直接保留报文边界，交给IP层；
+ 对于IP层交上来的UPD用户数据报，取出首部之后原封不动交个上传应用程序，这样的特性有利于实时传输。



> UDP数据报的组成？

+ UDP主要有两部分报文，数据部分和首部字段；
+ 首部有8个字节，由4个字段组成，每个字段两个字节；
+ 4个字段分别是：源端口、目的端口长度、校验和；
+ 计算校验和是还会加上「伪首部」，校验的是全部数据内容。



> TCP报文首部主要字段的含义？

+ TCP首部分为固定部分和扩展部分；
+ 固定部分包含了：
  + 源端口、目的端口：端口是运输层与应用层的服务接口；(16位，65536个)
  + 序号：报文段发送数据第一个字节的序号，TCP为数据流中每个字节编号；(32位)
  + 确认号：期望收到对方下一个报文段的数据的第一个字节序号；(32位)
  + 数据偏移：TCP报文的数据其实出距离TCP报文段其实多远，单位是4字节；(4位)
  + 保留字段：保留位今后使用；(6位)
  + URG：紧急字段，为1时表示紧急指针有效，告诉系统此报文有紧急数据，应尽快传输；
  + ACK：ACK=1，确认号字段有效，否则无效；
  + PSH：PSH=1，尽快交付接收应用进程，而不是等待缓存填满再交付；
  + RST：RST=1，TCP连接出现严重差错，必须释放里连接，重新建立运输连接；
  + SYN：SYN=1，是有一个连接请求或连接接收报文；
  + FIN：FIN=1，释放一个连接；
  + 窗口：让对方设置发送窗口的依据，单位为字节；(16位)
  + 校验和：校验首部和数据部分，校验是加上12字节伪首部；(16位)
  + 紧急指针：本报文中紧急数据字节数(紧急数据会放到报文段数据最前面，16位)
+ 可变部分：
  + 选项(长度可变)：最大报文段长度(MSS)，告诉对方自己接收报文段的数据字段最大长度；
  + 填充字段：还是首部长度是4字节整数倍。



> TCP可靠传输的实现？

【支持机制】

+ TCP通过：数据分块、序列号和确认应答、校验和、流量控制、拥塞控制、ARQ协议、超时重传；
+ 数据分块：应用层数据会被分割成TCP认为合适的发送数据库；
+ 序列号确认应答：TCP会为发送的数据每个字节编号，每次接收方收到数据都会对传输方进行确认应答；
+ 校验和：TCP将记录首部和数据部分的校验和，检查传输过程中报文段数据是否有差错，有差错则不确认；
+ 流量控制：为了避免对方来不及处理，TCP双方会维护固定的缓冲区，发送方发送数据量不超过接收端缓冲区；当接收方来不及处理发送方数据，会提示发送方降低发送速率，防止产生丢包。TCP通过滑动窗口协议来支持流量控制；
+ 拥塞控制：当网络中某个节点发送拥塞时，减少对网络中数据量的发送；
+ ARQ协议：发送完分组，会等待对方确认，收到确认之后才进行下面的数据发送；
+ 超时重传：TCP发出一个报文后，启动一个定时器，等待目的端确认收到这个报文段。如果超时没有接受，重复这个报文段。

【具体实现】

+ TCP连接的每一端必须设置两个窗口，发送窗口、接收窗口；
+ TCP机制通过字节序号进行控制，TCP所有确认基于序号确认而非报文段；
+ TCP两端的四个窗口经常处于动态变化，以适应不同的网络环境；



> ARQ协议？

+ ARQ，自动重传协议，TCP发出一个报文之后回去启动一个定时器，如果超时时间内没有收到确认，会自定将该数据报进行重传。这样可以使得接收方不需要请求发送方和重新请求魔鬼出错的分组，只需要不丢该分组确认即可。

+ 一发一确认的ARQ方式效率很低，通常使用的是**流水线传输**，即发送方连续发送多个分组，不必每发完一个分组就停顿下来等待对方的确认；对于接收方一般采用**累积确认**，即不必对收到的分组组个发送确认，而是对按序到达的最后一个分组发送确认即可。



> 流量控制？

+ 流量控制就是让发送方发送速率不要太快，要让接收方来得及接受，不要使网络发送阻塞；
+ TCP协议中的流量控制通过滑动窗口实现；
+ 当接收方来不及处理发送方的数据时，可以适当将滑动窗口变小，这样一来每次发送的数据就变小了；
+ 当接收方觉得对方发送的数据太慢，可以适当将滑动窗口调大，这样一来每次发送的数据就便多了；



> 拥塞控制及其算法？

+ 拥塞控制目的是让网络能承受现有的网络负荷，避免网络持续变差而进入瘫痪；
+ 拥塞控制是动态的过程，检查拥塞是困难的；
+ 拥塞控制主要有以下几种方法
  + 慢开始和拥塞避免：
  + 快重传和快恢复；

【拥塞窗口】

+ 发送方维持一个拥塞窗口，其大小取决于网络的拥塞程度，并动态变化；
+ 发送方让自己的发送窗口等于拥塞窗口；
+ 发送方控制窗口大小原则是，只要网络没有出现拥塞，拥塞窗口就增大一些，以便把更多分组发送出去；如果出现拥塞，拥塞窗口就减少一些，以减少注入为了中的分组中；

【慢开始算法】

+ 主机刚开始发送报文是，先设置拥塞窗口cwnd=1；
+ 没收到一个新的报文段确认，将拥塞窗口加1；
+ 通过上述的方法逐步增大发送端拿到拥塞窗口cwnd，使分组注入到网络的速率更合理；
+ 在使用慢开始算法时，没经过一次传输轮次，拥塞窗口cwnd加倍；
+ 慢开始算法的执行会受到「慢开始门限状态量ssthresh」限制；
+ 当cwnd大于ssthresh之后，不再使用慢开始算法，而改用拥塞避免算法；

【拥塞避免算法】

+ 拥塞避免的思路是个让拥塞窗口缓慢的增大，每经过一个RTT，不再把cwnd加倍，而是cwnd加1；

【出现拥塞】

+ 无论是慢开始还是拥塞避免阶段，只有发送方判断网络出现拥塞，就会被慢开始门限状态量减半；
+ 然后把拥塞窗口重新设置为1，执行慢开始算法；
+ 这样做的目的是迅速加锁主机发送到网络中的分组树，使得发送拥塞的路由器有足够时间吧队列中积压的分组处理完毕；

![image-20210913160131806](https://gitee.com/tobing/imagebed/raw/master/image-20210913160131806.png)

+ 乘法较少：网络慢开始还是拥塞避免阶段，出现一次超时，把慢开始门限值减半；
+ 加法增大：执行拥塞避免之后，在收到对所有报文确认好，cwnd加一，使其缓慢增大，防止网络过早出现拥塞。

【快重传】

+ 快重传可以使得在某些情况下可更早地重传丢失的报文段；

+ 快重传算法要求接收方每收到一个失序报文立即发出重复确认，这样可以让发送方及早知道**有报文段没有到达接收方**；
+ 发送方只要一连收到三个重复确认应当立即重传对方尚为收到的报文段；

【快恢复】

+ 发送端收到三个重复确认，执行「乘法计算」算法，对慢开始门限值减半，但接下来不执行慢开始；
+ 由于发送方认为网络可能没有发送拥塞，因此不再是慢开始，即不是将cwnd设置为1，而是设为慢开始门限值建表的数值，然后开始执行拥塞避免算法，是拥塞窗口缓慢的增加。

![image-20210913161115972](https://gitee.com/tobing/imagebed/raw/master/image-20210913161115972.png)



> 拥塞控制与流量控制的区别？

拥塞控制与流量控制的目的不一样：

+ 拥塞控制是保证无论能够承受现有的网络负荷，确保网络不瘫痪；
+ 拥塞控制是一个全局性的过程，涉及到网络行的所有主机、路由器，以及与降低网络传输性能能有关的所有因素；
+ 流量控制则是保证对方能够来得及处理，避免造成数据的丢包；
+ 流量控制是一个局部性的过程，通常设计的是发送端和接收端两个主机；



> TCP三次握手过程？

![image-20210914114842062](https://gitee.com/tobing/imagebed/raw/master/image-20210914114842062.png)

TCP连接连接前，服务器需要完成初始化只要会经历了以下过程：

1. 一开始，服务器进程先创建传输控制块TCB，准备接受客户端进程的连接请求；
2. 之后服务器处于LISTEN状态，等待客户端的连接请求；
3. 客户端在连接前首先创建传输控制TCB，准备连接到服务器；
4. 在打算连接的TCP服务器时，客户端发送一个连接请求报文（SYN=1）；
5. 服务器收到请求报文之后，如同意建立连接，则先客户端发送确认（SYN=1、ACK=1）；
6. 客户端在收到服务器的确认报文后，要先服务器进行确认，发出确认包（ACK=1）。



> 为什么需要三次握手？

1. 三次握手的主要目的是确认双方的收发功能都是正常的，确保双方能够进行可靠通信；
2.   如果使用两次握手，客户端知道服务器的收发功能是否正常，服务器却不知道客户端接收是否正常；
3. 第三次确认是防止已经失效的报文端突然传输给服务器端B，因此产生了错误；
4. 存在这种情况，客户端A发送的连接报文在网络中长时间滞留，以致延误到连接释放的某个时间点才到达B；
5. 此时A已经不想连接到B，但是对于B会把这次连接看做新的连接，并返回SYN_ACK；
6. 如果此时没有第三次握手，A和B的连接就已经建立完成，但是确没有通信，白白浪费了资源；
7. 有了第三次握手，在客户端收到SYN_ACK之后，发现无此报文，可以直接不理睬B，也不会向B发送数据。



> TCP释放连接的过程？

1. 主动关闭的一方A会先对方B发出连接释放请求；（FIN）
2. B收到A连接释放报文，会发出确认；（ACK）
3. 此时B会通知服务器A到B方向的数据传输关闭；【TCP处于版关闭状态】
4. 如果B没有要向A发送的数据，应用程序会通知TCP释放连接；（FIN+ACK）
5. A收到连接释放报文，必须发出确认；（ACK）
6. A在发出确认之后，必须要等待2MSL时间才进入关闭状态。



> 为什么挥手时不采用三次挥手？

+ TCP是双向通信，两个方向的通信必须要分别关闭；
+ 因为当主动方在数据传输结束发出连接释放请求之后，被动方可能还需要进行必要的数据传输；
+ 因此被动方会先发送ACK确认报文；
+ 等到被动方也没有数据再发送之后，则发出连接释放通知，对方确认之后TCP完全关闭。



> 为什么建立连接时三次握手，关闭连接时四次挥手？

+ 三次握手的目的是要确认TCP双方知道对方的收发功能是否；
+ 如果少于三次则会有一方无法完全知道另外一方的情况；
+ 由于TCP是双向通信的，由于一方关闭的时候，另外一方可能还要数据需要传递；
+ 因此两个方向的通信需要依次关闭，这样最少需要4次握手；



> TCP四次挥手、第四次挥手时一直丢包怎么办？

+ 主动方在发出第四次挥手之后会处于TIME_WAIT状态等待2MSL；
+ 在这段时间内如果第四次挥手由于丢包没有传到被动方，被动方会在超时之后重发FIN给主动方；
+ 这将导致主动方在等待2MSL之后断开连接，而被动方会不正常关闭连接；



> 为什么客户端最后要等待2MSL？

1. 保证主动关闭的一方最后发送的ACK报文能够到达对方；
2. 防止「已失效的连接请求报文段」出现在本连接；
3. 客户端发送完最后一个ACK报文之后，经过2MSL，可以使得本连接持续时间内产生的所有报文段从网络上中消失；
4. 这样可以使得下一个新的连接中不会出现就的连接请求报文段；



> 如果已经建立连接，但是客户端突然出现故障怎么办？

+ TCP设有一个保活计时器，服务器没收到一次客户数据，就重置保活计时器，保活计时器的时长通常是2小时；
+ 如果2小时没有收到客户端的数据，服务器会发送一个探测报文，以后每隔75秒发送一次；
+ 如果发送10个探测报文仍无客户端响应，服务器任务客户端出现了故障，接着关闭这个连接；



> UDP和TCP的区别？

|   区别   |        TCP         |        UDP         |
| :------: | :----------------: | :----------------: |
| 面向连接 |      面向连接      |       无连接       |
| 是否可靠 |        可靠        |       不可靠       |
| 传输形式 |       字节流       |     数据报文段     |
| 传输效率 |         慢         |         快         |
| 需要资源 |         多         |         少         |
| 应用场景 | 文件传输、邮件传输 | 即时通信、域名转换 |
| 首部长度 |     20~60Byte      |       8Byte        |



> TCP粘包问题？

【粘包是什么？】

+ TCP的传输格式是字节流，不会保留应用层的边界；
+ 如果发送方写入数据大于套接字缓冲区大小，将会发生拆包；
+ 如果发送发写入数据小于套接字缓冲区大小，TCP默认会Nagle算法；
+ Nagle算法会积累的一定数据量才会将这些数据包一起发送，这是将会发生粘包；
+ 如果发送方发送的数据太快，导致数据聚集在接收方缓冲区，将会发生粘包；

【如何处理粘包】

+ 消息头部添加消息长度字段，服务器获取之后可以获取消息头的时候解析消息长度，然后根据长度解析；
+ 固定消息数据的长度，服务端每次取数据的时候只取固定长度的内容，如果消息不够长使用空格补上；
+ 设置消息边界，即设置分隔符，服务器从数据量中按消息边界分离出消息内容，一般使用换行符。



> HTTP请求报文的组成部分？

+ HTTP请求报文包含了三部分：请求行、请求头部、请求体；
+ 请求行包含了：请求方法，如GET/POST；请求路径一般用URI表示、协议版本号常见的如HTTP/1.1；
+ 请求头部则包含了本次请求携带的信息，以键值对的方式进行传递；
+ 如常见的有host、Connection、User-Agent、Accept
+ 最后是请求体；



> HTTP响应报文的组成部分?

+ HTTP响应报文包含了三部分：状态行、响应头部、响应体；
+ 状态行包含了报文使用的协议版本号、表示该请求的处理状态码、对状态码的补充内容；
+ 响应头部包含了本次处理结果信息，以键值对方式进行表示；
+ 常见的有Location、Accept-Ranges、Server、Content、Last-Modified



> HTTP状态码以及其意义？

+ HTTP响应报文中的状态行表示了本次请求的处理结果；
+ 常见的状态码是100~500，规定是3位数；
+ 200：成功，表示请求已经被成功处理，常见的有200，206表示请求部分范围；
+ 300：重定向，表示完成的请求需要进行附加操作，场景的有301和302，分别表示永久重定向和临时重定向；
+ 400：客户端错误，表示请求有语法错误或请求无法实现，场景的有404、405；
+ 500：服务器错误，表示服务器处理请求的时候出现错误；

【临时重定向与永久重定向】

+ 301和302都不是资源重定向，完成本次请求需要到新的URI去请求；
+ 301表示永久重定向，即资源以及永久被移动了，旧的地址已经被永久删除，返回的信息会包含新的URI；
+ 301常用于新域名的更换、服务器更换等，需要通知浏览器和搜索引擎更新到新的地址；
+ 302表示临时重定向，即资源被临时移动了，旧的地址还在使用，客户端应该保持原有的URI；
+ 302常用于不重要功能入口的关闭，保证核心服务的正常运行，如双11关闭优惠卷系统，使更多的资源能够用于订单等热门系统，此时可以将优惠卷服务重定向到首页；
+ 需要注意重定向容易出现循环重定向的情况，一定要注意。



> 长连接以及短链接的区别？

+ HTTP协议依赖于TCP/IP协议，其运输层协议是TCP，HTTP请求的收发依赖于TCP连接的建立；
+ 以前每个HTTP请求建立都需要重新创建TCP连接，每个HTTP释放都会导致TCP连接释放，这种方式称为短链接；
+ 短链接的缺点就是比较消耗资源，对于频繁通信的两个节点，每次都要重新建立TCP连接；
+ 针对短链接存在的问题，HTTP协议在提出了长连接；
+ 使用长连接的时候，每次看可以在一个TCP会话中进行多次HTTP请求，减少了资源的消耗；
+ HTTP/1.1开始，默认使用长连接，会在报文头部使用connection=keep-alive表示；

> 长连接与短链接的使用场景？

+ 长连接常用于客户端连接数量少，且操作频繁的点对点通信，这样可以节省每次TCP的建立资源；
+ 短链接常用于客户端连接数较多的情况，如电商平台等；



> HTTP各个版本在功能上的演变？

【HTTP/1.1 vs HTTP/1.0】

+ HTTP/1.1与HTTP/1.0相比，主要多了缓存处理优化、解决带宽优化、错误通知管理、Host请求头、长连接等特性；
+ 缓存处理：与HTTP/1.1在HTTP/1.0基础上提供了更多用于控制缓存的字段，可以实现更加灵活的缓存控制策略；
+ 节约带宽：HTTP/1.1引入了对资源的访问请求，可以请求部分属性，除此之外利用这个特性可以并发请求数据；
+ 错误通知管理：与HTTP/1.0相比HTTP/1.1有了更加丰富的错误状态码；
+ Host请求头：HTTP/1.1头部添加了强制字段host，运行一个机器可以托管多个虚拟主机；
+ 长连接：HTTP/1.1默认使用长连接节省带宽。

【HTTP/2.0 vs HTTP/1.1】

+ HTTP/2.0与HTTP/1.1相比，主要添加了二进制编码方式、多路复用、头部压缩、支持服务器推送等特性；
+ 二进制数据传输，HTTP/2.0开始使用二进制编码方式；
+ 多路复用解决了HTTP/1.X存在的队头阻塞问题；
+ 强制性的头部压缩减少了数据包大小，提供了数据传输效率；
+ 注册服务器向客户端进行数据推送；



> 如何解决HTTP的无状态性？

+ 把每个请求作为与之前任何请求都无关的独立的事务。
+ 无状态设计将来服务器端你段集，不必动态分配存储空间处理进行中的会话；
+ 客户端事务中断，服务器不需为情侣服务器状态而做出相应；
+ HTTP协议可以通过引入Cookie和Session来记录状态；



> HTTP中Get和Post的区别？

+ GET和POST是HTTP协议中的两种请求方式；
+ 一般GET用于获取数据，POST用于提交数据；
+ GET请求的键值对会放到URI上，POST请求的信息会发送到请求体中；
+ GET请求可以被缓存；POST请求不会缓存；
+ GET请求会保存在浏览器历史添加到书签；POST请求不会被保存；
+ GET请求长度收到浏览器URL长度限制；POST请求的数据长度没有限制；
+ GET是幂等等的，POST是非幂等的；



> HTTPS与HTTP的区别？

+ HTTP是非安全协议，默认采用明文传输；HTTPS是安全协议，数据经过加密进行传输；
+ HTTPS主要基于HTTP引入了SSL/TLS一层来实现安全通信；
+ HTTPS默认端口是443；HTTP默认端口80；
+ HTTPS建立连接的步骤比HTTP建立连接的步骤更多，花费的更多资源；



> HTTPS握手的过程？

+ HTTPS握手主要分为两个：「非对称加密协商过程」与「对称加密传输数据过程」；
+ 非对称加密协商是指使用非对称加密体系来协商对称加密的密钥，主要流程如下：
  1. TCP三次握手建立TCP连接；
  2. 客户端发送「Client Hello」声明客户端使用的TLS版本号、支持的密码套件、随机数；
  3. 服务器端返回「Server Hello」声明客户端本次使用的密码套件、随机数；
  4. 服务器端返回「Certificate」数字证书，表明自己的身份；
  5. 服务器端返回「Server Key Exchange」服务器公钥；
  6. 服务器端返回「Server Hello Done」TLS握手；
  7. 客户端拿到服务器端返回的数字证书，对比操作系统的根证书，判断证书有效性；
  8. 客户端在验证了证书有效性之后，会根据密码套件生成客户端的公钥以及PreMaster发送给服务器；
  9. 客户端发送「Change Cipher Spec」表示非对称加密交换对称加密密钥结束，后面使用该密钥进行加密；



> HTTPS绝对安全吗？

+ HTTPS的安全需要依靠多方的安全，主要包含了：服务端数字证书安全、服务端数字证书CA的安全、操作系统根证书安全；
+ 服务端数字证书可以有自己签发，也可以由可靠的CA（数字证书授权机构）颁发，后者颁发的更加具有安全性；
+ 客户端拿到服务器端的数字证书之后需要配合本地操作系统根证书，校验CA是否是可靠的；
+ 因此要保证HTTPS安全起码要保证上述的安全；



> CA是什么？

+ CA，数字证书颁发机构，用于给用户办法数字证书；
+ 用户通过出示各种证明自己的材料，提出申请证书；
+ CA对资料通过审核之后，会为用户颁发数字证书以及对应的私钥；
+ 数字证书内容包含了用户身份、公钥以及CA对「用户身份、公钥」的数字签名；



> SSL与TSL？

+ SSL，安全套接层，位于OSI会话层，由网景公司发明，SSL发展到v3是改名为TLS；
+ TLS，运输层安全，由路由协议、握手协议、警告协议、变更密码协议、扩展协议等几个子协议组成；
+ 服务器和浏览器使用TLS建立连接时，需要使用一组密码套件来实现安全通信；



> URL与URI的区别？

+ URL，统一资源定位符，用于表示互联网上得到资源的位置以及访问这些资源的方法
+ 互联网的所有资源，都有唯一确定的URL；
+ URL一般由四部分组成：`协议://主机:端口/路径`；
  + 协议：可以是http或ftp等；
  + 主机+端口可以唯一确定互联网上主机的应用程序
+ URI，统一资源标识符**。用字符串标识某一互联网资源，URL标识资源的地点**；
+ 统一：固定统一的格式可以方便处理不同类型的数据，不用根据上下文环境识别资源指定的访问方式；
+ 资源：可以识别的任何dig你选哪个，如文档、图像、服务等，资源可以是单一的也可以是集合；
+ 标识符：可标识的对象；

![image-20210914220341553](https://gitee.com/tobing/imagebed/raw/master/image-20210914220341553.png)



> Cookie与Session认识？

+ HTTP无状态协议，不会对之前发生过的请求和响应的状态进行管理；
+ HTTP主要通过Cookie技术与Session技术来控制客户端状态；
+ Cookie技术通过在请求和响应报文中写入Cookie信息来控制客户端状态；
+ Cookie会根据从服务器发送的响应报文的set-cookie字段，通知快递保存cookie；
+ 当下次客户端访问的时候，客户端自动在请求报文中加入cookie值发送出去；

+ Session机制通过在服务器创建一个Session对象将用户信息通过



Cookie的不可跨域性？

Session的创建与使用过程？ 

Session的生命周期？

Cookie与Session的应用场景以及区别？

浏览器输入URL地址到显示主页的过程发生了什么？

路由器与交换机的区别？

DNS寻址过程？

常见应用层协议对应的端口？

FTP为什么使用两个端口？

