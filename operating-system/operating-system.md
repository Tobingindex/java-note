# Operating-System

## 操作系统概述

### 系统职责

操作系统主要有两个职责：对硬件进行管理和抽象，为应用提供服务并进行管理。

从硬件层面，操作系统需要包含两类功能：

+ 将复杂的、具备不同功能的硬件资源纳入统一的管理
+ 负责将硬件抽象成不依赖具体硬件特性的资源，核心是「将有限的、离散的资源高效地抽象为无线的、连续的资源」

从应用层面，操作系统主要包含两类功能：

+ 提供不同层次、不同功能的接口以满足应用的需求，提供不同类型的访问控制、应用间交互
+ 操作系统负责对应用生命周期进行管理，包含应用的加载、启动、切换、调度、销毁等

### 操作系统接口

从应用角度、操作系统需要提供不同的层次接口，主要包含了系统调用接口、POSIX接口、领域引用接口。

**系统调用接口**

应用程序通过操作系统内核提供的接口向内核申请服务，如**系统调用**。系统调用是用户态应用向操作系统内核请求服务的方法。

**POSIX接口**

POSIX，Portable Operating System Interface for uniX，可移植操作系统接口。

由于每个操作系统提供的系统调用各不相同，为了同一个应用程序在不同操作系统上的可移植性，逐渐形成了一些可移植的操作系统接口标准，其中包含了POSIX。

**领域应用接口**

在POSIX或操作系统调用之上面向不同领域的领域应用接口。

### 硬件结构

现在主流计算机采用的硬件结构是冯诺依曼结构。在冯诺依曼结构中主要包括三个主要部分。

+ 中央处理器：主要负责运算和逻辑控制。
+ 存储器：负责储存程序指令和数据，以及保存程序执行的中间结果。通常包括寄存器、CPU缓存、内存等。
+ 输入输出：负责与外界打交道，从外界获取输入，并将结果向外界输出。

CPU与软件之间的桥梁是指令集架构。指令集架构主要包含了指令集、特权级、寄存器、执行模式、安全扩展、性能加速扩展等诸多方面。

**指令集**

指令集通常包含一系列不同功能的指令，用于数据搬移、计算、内存访问、过程调用等。CPU在运行操作系统或应用程序时，实际上是执行它们被编译之后包含的指令。

**特权级**

为了隔离不同功能之间造成的影响，指令集往往会提供不同的特权级。常见的特权级有用户态和内核态。对系统功能进行用户态和内核态的拆分，可以使得在用户态程序发生奔溃时，不会或很难影响到内核态程序的正常执行，从而显著提高了操作系统的安全性与可靠性。

从用户态切换到内核态的常用场景有三种：

+ 应用程序需要调用操作系统提供的系统调用【同步】
+ 应用程序会执行了一条指令，而该指令触发了异常，如应用执行访存指令时，触发了缺页异常【同步】
+ 应用程序执行过程汇总，CPU收到了一个来自外设的中断【异步】

> 同步的CPU特权级切换是由CPU正在执行的指令导致；异步的CPU特权级切换是不是由CPU运行的应用程序的指令导致

在发生特权级切换时，CPU和操作系统需要共同协作，主要流程如下：

1. CPU读取向量基地址寄存器，获得**异常向量表**的基地址
2. 根据异常原因调用操作系统设置的相应异常处理函数
3. 执行相应函数前一般会保护应用程序的上下文
4. 执行相应的异常处理函数
5. 执行完毕操作系统会恢复应用程序的上下文返回

> 为了能够在处理异常时，应用程序信息不被破坏，CPU会应用程序的执行状态进行保存，状态信息主要包含了：程序计数器、异常原因、栈指针、程序状态字寄存器、错误地址寄存器等。

**物理内存与缓存**

与CPU处理速度相比，内存的访问速度较慢。为了降低CPU访存的开销 ，现代CPU中一般引入了缓存，用于存放部分物理内存中的数据。

当CPU需要向物理内存写入数据时，可以直接在CPU缓存中；

当CPU需要从物理内存中读取数据时，可以先在CPU缓存中查找；

如果没有再到物理内存中获取，并把取回的数据放入缓存中，以便加快下次读取的速度。

**设备与中断**

输入输出设备的种类繁多、功能丰富，是冯诺依曼中的主要组成部分。输入输出设备与CPU之间的交互方式主要有以下几种方式。

+ 内存映射输入输出(MMIO)：一种常见的CPU控制和访问设备的方式，原理是把输入输出设备和物理内存放到同一个地址空间，为设备内部的内存和寄存器也分配相应的地址。
+ 轮询：CPU不通过MMIO查看是否有响应的输入，这种会浪费CPU资源
+ 中断：设备通过向CPU发出中断来打断CPU执行，使得CPU处理这个中断

## 内存管理

为了保证不同的应用程序能够**高效又安全**地共同使用物理内存资源，现代操作系统普遍使用**虚拟内存**。在引入了虚拟内存之后，应用程序是面向虚拟内存编写而不再是面向物理内存编写；应用程序运行时只能使用虚拟地址，CPU负责将虚拟地址翻译成为物理地址，操作系统负责将设置设置虚拟地址与物理地址之间的映射。

使用虚拟地址主要有以下的好处：

+ 仅将应用程序实际使用的虚拟地址映射到物理地址，**通过了内存资源的利用率**。（高效性）
+ 每个应用程序只能看到自己的虚拟地址空间，**保证了不同应用程序内存之间的隔离**。（安全性）
+ 每个应用程序的虚拟地址空间是统一的、连续的，**减低了编程的复杂性**。（透明性）

### 物理地址与虚拟地址

物理内存可以看作是大的数组，每个字节可以通过唯一的地址进行访问，这地址称为**物理地址**。在引入了虚拟地址之后，应用程序使用**虚拟地址**访问存储在物理内存中的数据和代码。虚拟地址转换为物理地址的过程，称为**地址翻译**。

在CPU中内存管理单元（MMU）负责地址翻译工作。当需要访问物理内存设备时，MMU翻译出的物理地址将会通知系统总线传到相应的物理内存设备，从而完成物理内存的读写操作。由于指令通常时保持到磁盘中，使用时需要加载到物理内存中，为了加速地址翻译，现代CPU通常会使用转址旁路缓存（TLB），嵌入到MMU。

#### 分段与分页

MMU将虚拟地址转换为物理地址的机制主要有两种：分段机制和分页机制。

**分段机制**

分段机制下，操作系统以「段」的形式来管理/分配物理内存。

应用程序的虚拟地址空间由若干不同大小的段组成，如代码段、数据段等。当时CPU访问虚拟地址空间的某个段时，MMU会先去查询段表，得到该段对应的物理内存区域。

在分段机制下，虚拟地址分为两部分：段号+段内地址

+ 段号：标识虚拟地址属于虚拟地址空间的哪一个段；
+ 段内地址：相对于该段的起始地址的偏移量。

使用分段机制操作系统可以实现物理内存资源的离散分配，但是这种方式容易导致**外部碎片**的问题。

**分页机制**

分页机制是被现代操作系统更为广泛使用的机制。

分页机制的基本思想是将应用程序的虚拟地址空间划分为连续的、等长的物理页。虚拟页和物理页固定且相等，这样可以使得操作系统方便为每个应用程序构造**页表**，即虚拟页到物理页的映射关系表。

分页机制上的虚拟地址有两部分组成：页号+页内偏移。在地址翻译时

+ MMU首先根据页号定位到该应用程序应用程序的页表中找到存储的物理页号
+ 根据物理页号对对应的物理页其实地址加上虚拟地址的**页内偏移**得到最终地址

**页号**==>页表==>物理页号==>物理页基址==>加上**页内偏移**==>最终地址

分页机制下，操作系统也能实现物理内存资源的离散分配；除此之外，分页机制按照固定的大小分配物理内存，使·得物理内存易于管理，可以**有效避免分段机制的外部碎片问题**。

#### 分页内存管理

现代操作系统广泛使用基于分页机制的虚拟内存设计实现。

在分页机制中页表是关键，主要负责记录虚拟页到物理页的映射关系。通过简单的使用一张简单的单级页表来记录映射关系，该页表将会耗费海量的空间。如对于64位虚拟地址空间，假如每页大小4KB，页表每项8字节，页表需要33554432GB，这显然是不合理的。

为了压缩页表大小，操作系统引入了**多级页表**。在使用多级页表时，一个虚拟地址被分为虚拟页号和业内偏移。其中虚拟页号被分为k个部分，每一部分虚拟页号对应该虚拟地址在该级页表中的索引。当任意一级页表某个条目为空，条目对应的下一级页表不需要存在，因此类似。因此对于多级页表允许整个表结构出现空洞，这样一来就可以节省大量的空间。

对于一个4级页表，MMU在翻译64位虚拟地址时

1. 首先根据**页表基地址寄存器**的物理地址找到0级页表，将虚拟地址的虚拟页号0作为**页表项索引**，读取第0级页表中的对应页表项；
2. 将0级页表项中存储的下一级页表页的物理地址，将虚拟地址的虚拟也号1作为页表项声音，读取第1级页表中对应页表项；
3. 以此类推，MMU将会在第3级页表页中的页表中找到对应的物理页号，结合虚拟地址的业内偏移可以获得最终地址。

```java
// 64位虚拟地址
-----------------------------------------------------------------
| 第0级虚拟页号 | 第1级虚拟页号 | 第2级虚拟页号 | 第3级虚拟页号 | 页内偏移 |
-----------------------------------------------------------------
页表基地址寄存器 + 第0级虚拟页号 ==> 第1级虚拟页物理地址
第1级虚拟页物理地址 + 第1级虚拟页号 ==> 第2级虚拟页物理地址
第2级虚拟页物理地址 + 第2级虚拟页号 ==> 第3级虚拟页物理地址
第3级虚拟页物理地址 + 第3级虚拟页号 + 页内偏移 ==> 最终物理地址
```

显然多级页表结构能显著压缩页表大小，但是会导致地址翻译的时间变长。为了减少地址翻译的访存次数，MMU引入了**转址旁路缓存**(TLB)来加速地址翻译。TLB缓存了虚拟页号到物理页号的映射关系。使用TLB时，MMU会先把虚拟页号作为键去查询TLB中的缓存项，找到则无需查询页表(TLB hit)，反之没有找到(TLB miss)。

在引入TLB，不可避免会存在数据一致性问题，即TLB与当前页表页的内容一致性问题。存在数据一致性的根本问题是，页表发生了改变，但是TLB却没有做出相应的更新。

因此处理TLB缓存一致性问题最简单的方案就是在页表切换时(应用程序切换)时主动刷新TLB。但是这种处理方式会导致每次在切换完应用程序执行时，总会发生TLB未命中的情况，进而造成性能损耗。

为此，更好的处理方案是TLB缓存项打上TAG。这种方案下，操作系统位不同的应用程序分配不同的ID用于标识身份，再将这标签ID写入到TLB的TAG位置。这样一来，TLB缓存项可以区分属于不同应用程序，在切换页表时，TLB会判断页表项是否属于当前应用程序，如果是操作系统不需要清空TLB缓存项。

#### 缺页与换页

由于虚拟内存接近于无限大，而物理内存的容量有限，因此当物理内存不足时，需要将部分内存持久化到磁盘中，这样一来就可以腾出物理内存给新的应用使用（换出）。

虚拟内存中通过「换页机制」来实现透明的物理内存的换入换出。在这个过程中，存在分配给应用程序但映射到物理内存的虚拟机内存。当应用程序访问这部分虚拟内存时，会触发一个「缺页中断」。此时CPU会运行操作系统预先定义的缺页异常处理函数，该函数会找到一个空闲的物理页，将之前持久化到磁盘的数据内容重新加载到物理页中（换入）。

由于换页过程存在磁盘操作，操作系统往往会通过「预取机制」进行优化：当发生换入操作，预测哪些页即将会被访问，将其提前换入物理内存中，从而减少发生缺页异常的次数。

#### 换页策略

在分配物理页时，当空闲的物理页已经用完或小于某个阈值，操作系统会根据「换页策略」选择一个或一些物理页换出到磁盘以便让出空间。当已被换出的物理内存再次被访问时，需要重新读盘，十分耗时。因此「换页策略」对性能影响很大。

总的来说，换页策略的目标就是猜测用户页的使用规律，从而减少缺页异常代理的性能消耗。经典的「换页策略」有：

**OPT策略**

在选择被换出的页时，优先选择未来不会再访问的页，或最长时间内不会在访问的页。

理论最优的换页策略，实际中很难实现，通常用于衡量其他换页策略的优劣。

**FIFO策略**

优先选择最先换入的页进行换出。

最简单，时间开销低的换页策略。

**Second Chance策略**

FIFO改进版，实现与FIFO策略类似。

操作系统维护先进先出队列用于记录换入物理内存的物理页号，在此基础上为每个物理页号维护一个访问标志位。

如果访问的页号在队列中会为其添加一个访问标识。当要寻找缓存的内存页时，优先查看队头的页号，如果该也存在访问标识，则将其清零，取下一页机型判断；如果不存在访问标识，直接换出。

**LRU策略**

选择被换出页时，优先选择最久未被访问的页。

LRU策略是基于：过去薯条指令频繁访问的页很可能在后继的数条指令中被频繁访问。

实现：操作系统维护一条链表，按照内存页的访问顺序将内存页号插入到链表；每次访问内存，把刚刚访问的内存页号调整到链表尾部；每次选择换出首部的页。

**MRU策略**

选择被换出页时，优先选择最近被访问的页。

MRU策略是基于：程序不会反复访问相同的地址。如在媒体流数据通常每一帧数据只会读取一次。

**时钟策略**

将换入物理内存的页号排成一个时钟形状。该时钟有一个针臂，执行新换入内存的页号的后一个。同时为每个页号维护一个访问标识。

每次选择换出页号时，从针臂指向的页号开始检查，如果当前页号存在访问标识，则将其置空，并且针臂移动到下一个页号，如此重复。

### 虚拟内存功能

虚拟内存抽象可以使得应用程序能够拥有一个独立而连续的虚拟地址空间。其内部通过页表与硬件的配合能够在对应用程序透明的情况下自动进行虚拟地址到物理地址的翻译。除此之外虚拟机内存还可以实现以下功能。

#### 共享内存

共享内存允许同一物理页在不同的应用程序间共享。

其内部实现原理是不同的虚拟页号被映射到相同的物理页上，不同的虚拟页可以读取到相同的内容，也可以擦看到对方修改的内容。

<font style="color:red">**通过共享内存可以让不同的应用程序之间相互通信、传递数据。**</font>

#### 写时拷贝

写时拷贝技术允许不同应用程序之间以**只读**的方式共享一段物理内存。 一旦某个应用程序对该内存空间就行了修改，就会触发缺页异常(违反权限的缺页异常，而非未映射的缺页异常)，CPU此时换转向指向异常处理函数。在异常处理函数中会发现缺页异常是由于出现修改了只读内存产生的，于是操作系统会在物理内存中将缺页异常对应的物理页重新拷贝一份，并将新拷贝的物理页以可读可写的方式重新映射给触发异常的应用程序，此后恢复应用程序执行。

通过写时拷贝，一方面可以节约物理内存资源，如不同的应用程序以写时拷贝的方式映射相同的动态链接库；另一方面可以让父子进程以只读的方式共享全部内存数据，避免内存拷贝带来的时间和空间开销。

#### 内存去重

基于写时拷贝，可以实现内存去重。

操作系统可以定期在内存中进行扫描具有相同内存的物理页，并且找到映射这些物理页的虚拟页；然后只保留一个物理页，将其他具有相同内容的其他虚拟页都用写时拷贝的方式映射到同一个物理页中。

该功能有操作系统主动发起，对用户态应用程序完全透明。

#### 内存压缩

内存压缩的目标是节约内存资源。

当内存资源不充足时，操作系统选择一些「最近不会太经常使用」的内存页，压缩其中数据，从而释放出更多空闲的内存。应用程序需要访问这部分内存时，只需要将其解压缩即可。所有操作都在内存中完成，相比于将数据置换出磁盘，更为高效。

在使用了内存压缩，即使发生了写盘操作，引用内存数据时经过压缩之后，体积会明显减少，写盘的性能损耗也会降低。

#### 大页

TLB命中率越高，其地址翻译的性能开销越低。

内存越大，占用的内存项越多，从而会导致TLB缓存项占用的越多，很难保证高的TLB命中率。

通过大页机制可以有效缓解TLB缓存项不够用的问题。即在页表项中使用一位来标识对应的页表是页表页、2MB、1GB页。

使用大页机制，一方面可以减少TLB缓存项的使用，从而有机会提高TLB的命中率；另一方面可以减少页表的级数，从而提高查询页表的效率。

### 物理内存分配与管理

#### 目标与评价指标

物理内存分配有两个重要评价维度。

+ 更高的内存资源利用率，尽可能减少资源浪费。资源浪费主要指内存碎片问题。
  + 外部碎片：单个空闲内存董晓宇分配请求的内存，但加起来足够；
  + 内部碎片：分配的内存大于实际使用的内存。
+ 更好的内存分配性能，尽可能降低分配延迟和节约CPU资源。

#### 伙伴系统

伙伴系统被广泛用于分配连续的物理内存页，基本思想是将物理内存划分成连续的块，以块为基本单位进行分配。

不同块之间大小可以不同，但是每个块都由一个或多个连续的物理页组成，物理页的数量必须是2的n次幂。

当一个请求需要分配m个物理页时，主要经历一下步骤：

1. 伙伴系统将寻找一个大小合适的块，该块包含了2^n个物理页{ 2^(n-1) < m <= 2^n }
2. 处理分配请求时，大的块可以分裂成两个小一号的块，两个块互为伙伴
3. 分裂得到的块可以继续分裂，直到得到一个大小合适的块去服务相应的分配请求
4. 在一个块被释放后，分派器会找到其伙伴块，若伙伴块也处于空闲状态，则将两个伙伴合并，形成大一号的空闲块，然后尝试继续向上合并
5. 由于分裂操作和合并操作都是级联，因此能够很好缓解外部碎片问题。

#### SLAB分派器

伙伴系统最小分配单位是一个物理页（4KB），但是大多数情况下，内核需要分配的内存通常是几十个字节或者几百个字节，远小于一个物理页大小 。<font style="color:red">**因此，如果仅仅使用伙伴系统来进行内存分配会存在大量的内部碎片。**</font>为了解决这个问题，操作系统引入了SLAB分派器（SLAB又可以细分为SLAB、SLUB、SLOB）。

SLUB分派器可以满足操作系统频繁的分配小对象的需求，其依赖于伙伴系统进行物理页的分配。

SLUB把伙伴系统分配的大块内存进一步分成小块内存进行管理。一方面由于操作系统频繁分配的对象大小相对比较固定；另一方面为了避免外部碎片问题，因此SLUB分派器只分配规定大小的内存块，统称为2^n字节。

SLUB向伙伴系统申请一定大小的物理内存块，并将获得的物理内存作为slab。slab会被划分为等长的小块内存，并且内部空闲小块内存会被组织成空闲链表的形式。

SLUB系统中存在两个重要指针：

+ current：仅指向一个slab，所有分配请求从该指针指向的slab获取空闲内存块；
+ partial：指向所有拥有空闲块的slab组成的链表

当SLUB接收到一个分配请求，先定位到能满足请求大小最接近的内存资源池，然后后从current指针指向的slab获取一个空闲块返回即可。如果current在取出一块空闲块之后不再拥有空闲块，则从partial取出一个slab嫁给current指针。如果partial指针指向的链表为空，则SLUB分派器向伙伴系统重新申请，分配新的为了内存作为新的slab。

#### 物理内存与CPU缓存

缓存是缓解不同设备之间速度差异，提高系统整体性能的利器。

但是与物理内存相比，缓存要小很多；物理内存中的数据根据物理地址以「缓存行」的粒度放到CPU缓存中，如果缓存已经满或存在冲突，会根据预设的替换策略替换某个缓存行。

操作系统在给应用操作分配物理页时，需要尽可能分配不会造成缓存冲突的物理页，这样可以使得尽可能多的应用数据存放到缓存行中，从而充分利用缓存大小来提高应用访存性能。

**软件方案：染色机制**

把能够存放在**缓存不同位置**的物理页标记不用的颜色，在为连续虚拟内存页法分配物理页时，优先选择不同颜色的物理页进行分配。（同一种颜色的物理页会发生缓存冲突，引用连续虚拟内存页通常可能在短时间内被相继访问，分配不同颜色的物理页可以让被访问的数据都处于缓存中，不应冲突，从而避免缓存为命中的开销）

**硬件方案：Intel CAT**

一般而言，CPU最末级缓存会被多个CPU核心共享。由于每个CPU核心可以同时运行不同的应用程序，这些程序会竞争最末级缓存的资源，从而看由于相互影响导致应用程序产生性能抖动。

Intel 缓存分配技术运行操作系统设置应用程序能够使用的最末级缓存的大小和区域，从而实现最末级缓存资源在不同应用程序之间的隔离。

## 进程与线程

操作系统为了管理程序的运行，提供了进程的抽象。每个进程都对应了一个运行中的程序，操作系统通过对进程的管理实现对运行中应用程序的管理。

在进程的基础上，操作系统通过上下文切换机制来实现进程的暂停、切换和恢复，从而实现CPU资源的共享；同时利用虚拟内存机制，操作系统为每个线程提供了独立的虚拟地址空间，使得多个进程能够安全、高效地共享物理内存。

随着计算机的发展，操作系统在进程的基础上做出了满足不同场景的抽象。

+ 基于进程(process)间数据不易共享、通信开销大等问题，在进程内部引入了 更加轻量级的执行单位「线程(thread)」。
+ 又由于线程的切换需要导致上下文的切换，涉及到内核态与用户态的切换，于是又引入了「纤程(fiber)」的抽象

### 进程

#### 进程的状态

现代计算机中，进程可以处于以下几种状态：

+ 新生（new）：一个线程各个被创建出来，但未完成初始化，不能被调度；
+ 就绪（ready）：进程可以被调度，但未被调度器选择；
+ 运行（running）：进程正在CPU上运行。一个进程执行一段时间后，调度器可以选择中断它的执行并重新将其放到调度队列，此时线程会从运行转到就绪；
+ 阻塞（blocked）：进程需要等待外部事件，展示无法被完成调度；
+ 终止（terminated）：进程已经完成执行，且不会被调度。

> 进程状态的变化

```c
#include <stdio.h>
#define LEN 10
int main(int argc, char *argv[]) {
    char name[LEN] = {0};
    fgets(name, LEN, stdin);
    printf("Hello %s\n", name);
    return 0;
}
```

程序在Shell运行的过程中，该程序运行时对应的进程的状态会发生以下的变化：

1. 当用户按下换车，Shell接收到命令，请求内核态创建相应的继承以处理命令。内核创建出新线程时，线程未初始化完成，处于new状态；
2. 内核对进程需要的数据结构进行初始化，并将其交给调度器，加入运行队列，使其变为ready状态；
3. 调度器选择该进程执行，进程变为running状态，可以开始执行main函数；
4. 进程执行到fgets函数，需要接受用户输入，进程变为blocked等待用号输入；
5. 用户在键盘中输入「haha」并回车，进程重新进入running状态，并输出「haha」；
6. 进程执行完main函数，会到内核，变为terminated状态，内核会回收相应资源。

#### 进程的内存布局

进程具有独立的虚拟内存空间，主要结构如下：

+ 用户栈：保存进程需要的各种临时数据。自顶向下；
+ 代码库：进程执行时需要依赖的共享代码库，如libc，这些代码库会被映射到用户栈下方的虚拟地址处，并标记为只读；
+ 用户堆：堆管理进程动态分配的内存。自底向上；
+ 数据与代码段：原本保存在进程需要执行的二进制文件中，进程执行前操作系统将它们载入虚拟地址空间中。其中数据段主要保存全局变量值，代码段保存进程执行所需的代码；
+ 内核部分：每个进程的虚拟地址空间都映射了相同的内核内存。进程运行时内核内存对其不可见，只有当进程进入到内核态，才能访问内核内存。与用户态类似，内核部分也有内核需要的代码和数据段，当进程由于中断或系统调用进入内核，会使用内核的栈。

```c
=============
|内核代码与数据|  
-------------
|  内核栈    |
+++++++++++++
|  用户栈↓   |     
-------------
|  代码库    |     
-------------
|  用户堆↓   |     
-------------
|   数据    |
-------------
|   代码    |
=============
```

#### PCB与上下文切换

内核中每个进程对应一个进程控制块，在进程控制块中记录了进程的标识符、状态、虚拟内存状态、打开的文件等。

进程的上下文记录了进程运行时的寄存器状态，能够用于保存和恢复一个进程在处理器上运行的状态。当操作系统需要切换当前执行的进程时，会使用「上下文切换」机制。该机制会将当前一个进程的寄存器状态保存到PCB，然后将下一个进程先去保存的状态写入到寄存器中，从而切换到该进程执行。

#### Linux的进程实现

> 进程创建：fork

Linux进程一般是通过调用fork接口，从已有的进程中「分裂」出来。fork接口简单，不接收任何参数，返回值是当前进程的PID。

当一个进程调用fork，操作系统会为该进程创建一个几乎一模一样的子进程。fork刚刚完成时，两个进程的内存、寄存器、程序计数器等状态都完全一致；但两者是完全独立的进程，拥有不同的PID和虚拟内存空间，在fork完成之后两者各自独立执行，互不干扰。

尽管fork实现简单，但是其背后的是实现复杂。拥有调用fork之后父子进程的状态存在大量共享，因此会造成很多不确定的行为。

> 写时拷贝在进程中的应用

再去fork会将父进程的物理内存完全拷贝一份，并映射到子进程的内存空间。这种方式在很多情况下会导致内存浪费，如对于一些虚拟内存是只读的，父子进程可以同时使用同一份，没必要对其进行拷贝。其次，引用进程通常是在fork值立即执行exec以载入新的可执行文件，重置地址空间，之前的内存拷贝完全失去了意义。

在现代操作系统这个，会基于写时拷贝技术对fork进行优化，对于只读虚拟页，父子进程可以共享这些页，减少拷贝的开销；对于容易发生改变的虚拟页，如果出现写操作，会触发写时拷贝，有操作系统负责处理。

> 进程的执行：exec

fork完成之后，可以得到一个与父进程几乎完全相同子进程，但有时候用户需要在子进程中执行与父进程完全不同的任务。如用户会在Shell中输入各种命令，Shell会为这些命令fork创建出新的进程。但这些进程需要执行用户指定的二进制文件，而不是进行执行Shell程序。为了实现这个目标，Linux提供exec接口。

exec实际上有一系列接口组成，存在多个变种，如：

```c
int execve(const char pathname, char *const argv[], char *const envp[])
```

执行上述命令，操作系统会完成以下步骤：

1. 操作系统会根据pathname对应的路径，将可执行文件的数据段和代码段载入当前进程的地址空间中；
2. 重新初始化堆和栈；
3. 将PC寄存器设置到可执行文件代码段定义的入口点，该入口点最终会调用main函数；
4. 对于C程序的main函数`int main(int argc, char *argv[]){....}`，execve被调用后，操作系统会计算argv的数量，并将其和argv一起复制给main函数作为参数执行。

> 进程的管理

Linux中进程通过fork创建，操作系统会以fork作为线索记录进程之间的关系，不同进程之间会形成进程树是结构。通过进程树结构，内核为进程建立了冷链箱，并在此基础上提供了监控、回收、信号分发等一系列功能。

Linux中进程可以使用wait操作对其子进程进行监控。通过wait操作，父进程可以监控子进程是否已经退出、暂停或重启。除此之外，wait操作还可以用于回收已经运行结束的子进程和释放资源。**如果父进程没有调用wait操作，或没来得及调用wait操作，技术子进程已经终止，它占用的资源也不会完全释放，这种进程会成为僵尸进程。**这些僵尸进程会占据可用的PID，可能会导致后继fork操作因为内核资源不足而失败。但如果父进程退出，子进程的信息不再被父进程使用，也没必要保留它们，这时所有父进程创建的僵尸进程都会被内核第一个进程init通过wait方式回收。

为方便应用程序进行进程管理，内核定义了多个进程组合而成的小集合题，即**进程组**和**会话**。

进程组是进程的集合，可以由一个或多个进程组成；会话是进程组的集合，可以由一个或多个进程组构成。会话将进程组根据执行状态分为**前台进程组和后台进程组**。

控制终端进程是会话与外界进行交互的「窗口」，负责接收从用户发来的输入。当用户启动一个Shell，Shell就对应于一个会话。如果用户在Shell中输入Ctrl+C，终端进程会受到一个SIGINT信号，并将其发送到前台进程组处理，该信号一般会导致前台进程组的所有进程退出。

> fork过时了吗？

如今，fork仍广泛运用于Shell、Web服务器、数据库等应用中，如Redis以AOF写日志的时候，会通过fork的方式来创建出一个新的进程来进行复制，从而避免对主线程的阻塞。但随着计算机系统的发展和场景的变化，fork的局限性也越发暴露出来。

fork的优点是设计简洁，无需参数。fork与exec组合可以认为是将进程创建过程的进一步解耦，fork为进程搭建了骨架，exec为进程添加了血肉，两者分工清晰。除此之外fork还强调了进程之间的联系，为进程的管理提供了便利。如在Web服务器中，服务器会为每一个请求单独创建一个进程，由于这些进程的逻辑很相似，因此可以通过fork的方式异常创建多个进程来应对用户请求。

fork的缺点主要包含了fork变得关于复杂、性能太差、潜在安全漏洞。

### 线程

早期操作系统进程时管理运行程序的最小单位，但如今随着硬件的发展，计算机具有更多的核心，程序的可并行度提高，进程的抽象开始显得笨重。

+ 创建进程的开销较大，需要完成创建独立的地址空间、载入数据和代码段；
+ 进程拥有独立虚拟地址空间，在进程间通信和同步比较麻烦，一般只能基于共享虚拟页或进程间通信；

因此操作系统在进程内部添加可独立执行的单元：「线程」。<font style="color:red">**同一进程内的线程可以共享进程的地址空间，但各自保存运行时所需的状态（上下文）。**</font>之后，线程取代进程，称为操作系统调度和管理程序的最小单位。

#### 多线程地址空间

在引入了线程之后，进程的地址空间有所改变。多线程的地址空间主要有两个重要特征：

+ 分离的内核栈与用户栈：线程的运行相对独立，进程为每个线程准备里不同的栈，以供它们存放临时数据。内核中，每线程也有对应的内核栈。但线程切换到内核中自行，它的栈指针会切换到对应的内核栈；
+ 共享的其他区域：进程除了栈以外的其他区域有进程的所有线程共享。当同一个进程多个线程需要动态分配（malloc），它们的内存分配操作都在同一个堆上完成。此时需要使用同步原语来正确地获取到可用的内存空间。

```c
=============
|内核代码与数据|  
-------------
|  内核栈1   |
|  内核栈2   |  【分离】
|  内核栈3   |
+++++++++++++
|  用户栈1   |     
|  用户栈2   |  【分离】
|  用户栈3   |     
-------------
|  代码库    |     
-------------
|  用户堆↓   |     
-------------
|   数据    |
-------------
|   代码    |
=============
```

#### 用户态与内核态

根据线程由用户态应用还是由内核创建与管理，线程可以分为：

+ 内核态线程：操作系统调度器直接管理；
+ 用户态线程：比内核态线程更加轻量，创建开销更小。

为了实现用户态与内核态线程协作，操作系统会创建两类线程之间的关系（多线程模型）。

+ 多对一模型：多个用户态线程-->单一内核态线程，简单，每次只允许一个用户态线程进入内核，多个是被阻塞；
+ 一对一模型：一个用户态线程-->单一内核态线程，更好的扩展性，但创建内核线程开销会随着用户态线程数量增加而不断增大（一般系统会限制用户态线程数量）；【Linux和Windows】【主流】
+ 多对多模型：N个用户态线程-->M个用户态线程（N>M），既减少多对一的阻塞问题，又解决了一对一的创建过多性能开销大问题，但是管理变得复杂。【macOS和IOS的GCD】

#### TCB与TLS

TCB：线程控制块用于保存线程的自身相关的信息，包含了线程的运行状态、内存映射、标识符等信息。

TLS：线程本地储存可以实现「一个名字，多份拷贝」的全局变量，当某个线程对TLS变量赋值，只会修改的拷贝，不会对其他线程造成影响。（类似于Java的ThreadLocal）

### 纤程

主流操作系统采用的都是一对一的线程模型，用户态线程与内核态线程具有一一对应的关系，用户态线程的执行几乎完全受到操作系统调度器的管理。但随着计算机发展：

+ 应用程序变得越来越复杂，与系统调度器相比，应用本身对线程的语义以及执行状态更加了解，可以做出更优的决策；
+ 用户态线程更加轻量级，比内核态的创建和切换的开销低很多，更多地使用用户态线程有利于提高整个系统的可扩展性。

在上述背景下，操作系统开始提供更多对用户态线程（纤程）的支持。

#### 纤程的好处

在生产者消费者模型中，生产者负责生产数据，消费者负责消费数据。

假如有一个进程拥有两个线程，一个是生产者，另一个是消费者。由于两个线程共享同一地址空间，生产者可以在共享内存中直接写数据，供消费者使用。

假如计算机只有一个处理器，生产者生成数据到消费者消费数据至少需要经历一次上下文切换，才能完成数据处理。但实际中，处理器运行了多道程序，调度器并不知道生产者与消费者之间的关系，因此不一定优先选择消费者进行调度。经过生产者已经生成数据，但由于上下文切换的开销以及调度器的选择，消费者可能需要经历较长的延时才能开始处理数据。为了消除这部分延迟，应用程序可以使用纤程。【应用程序比系统的调度器对线程本身执行状态更加了解】

#### 纤程上下文切换

操作系统可以通过中断的方式来抢占当前CPU并进行上下文切换，这种切换是强制的。【抢占式多任务处理模式】

纤程不具备使用中断抢占其他纤程的权限，因此无法使用上述的模式。因此纤程库一般会提供yield接口，暂时放弃CPU，允许其他纤程的调度。【多合作式多任务处理模式】

> 一般将程序语言提供的纤程支持称为协程。

### 进程间通信

多进程协作存在以下三点优势：

1. 将功能模块化，避免重复造轮子；
2. 增强模块间的隔离，提供跟前的安全保障；
3. 提供应用的容错能力。

进程间通信（Inter-Process Communication，IPC）是多进程协作的基础。IPC只是需要两方参与：发送者和接收者。

+ 发送端将一段定长数据发送给接收者；【开始】
+ 发送者等待接收来自接收者的返回数据；
+ 接收者在接收到数据会根据自己的应用逻辑处理数据，并将处理结果返回发送者；【结束】

在不考虑进程间通信，发送者与接收者两个进程被内核隔离，处于不同的地址空间，其系统资源也是相互隔离。

为了实现进程间通信，一种简单的做法就是在两个进程的地址空间中，分别有一段虚拟地址空间映射到同一段物理内存(共享内存)，两个进程通过共享内存进行通信。

#### 宏内核进程间通信

宏内核下，典型进程间通信方式包含：管道，System V的消息队列、信号量、共享内存，Linux信号机制，套接字机制。

**管道**

管道是两个进程间的一条通道，一端负责投递，另一端负责接收。

管道是单向的IPC，内核中通常使用一定缓冲区来缓冲消息，通信的数据是字节流，需要应用自己解析。

管道在UNIX系列系统中会被当作一个文件。内核会为用户态提供代表管道的文件标识符，让用户态可以通过文件系统相关的系统调用来使用。管道的创建会返回一组（两个）文件描述符。

实际上管道不会使用储存设备，而是内存作为数据的缓冲区。这是因为管道是为了通信，一没有持久化的需求，二需要保证数据传输的高性能。

在经典UNIX实现中，可以根据其创建方式将管道分为两种：命名管道和匿名管道。

+ 匿名管道：通过pipe系统调用创建，创建的同时进程会拿到读写的两个文件描述符。由于管道没有全局名字，因此只能通过两个文件描述符使用它；
+ 命名管道：通过命令mkfifo创建，创建过程中指定一个全局文件名，这个文件名指代一个具体的观点。通过这种方式，只要两个进程通过相同管道名进行几创建，就可以实现在任意两个进程间建立管道的通信连接。

> 管道使用：如使用`pa aux | grep java`查看java相关进程时，包含了两个命令，通过Shell的管道符号`|`，将第一个命令的输出投递到一个管道中，而管道对应的出口是第二个命令的输入。
>
> 匿名管道使用：匿名管道通常结合fork的方式来创建父子进程间的连接。父进程实现通过pipe创建对应的管道两端，然后通过fork创建出子进程。由于子进程可以继承文件描述符，因此父子进程限度与通过fork的继承完成了一次IPC权限的分发。父子进程可以通过管道进行进程间通信。需要注意的是，完成继承后，父子进程会同时用于管道两端，此时需要父子进程主动关闭多余的端口，否则可能导致通信出错。

**System V 消息队列**

消息队列是宏内核中唯一一个以消息为内核数据抽象的通信方式。宏内核应用可以通过消息队列发送消息以及接收消息。发送和接受接口由内核提供。消息队列是一种非常灵活的通信机制。支持同时多个发送者和多个接收者。

Linux中为消息队列中的每个消息提供了类型的抽象，使得消息的发送者和接收者可以根据类型来选择性地处理消息。

消息队列的操作一般被抽象为四个基本操作（系统调用）：msgget、msgsnd、msgrcv和msgctl。

+ msgget：允许进程获取已有的消息队列的连接，或创建一个新的消息队列，消息队列允许任意数量的进程连接到同一通信连接上；
+ msgctl：可以控制和管理一个消息队列，如修改消息队列的权限信息或删除消息队列；
+ msgsnd：可以往消息队列中发送消息，发送成功标志是消息被放到队列上，同一时间可以有多个进程同时往队列发送消息，当队列已满时，发送消息的操作会被阻塞；
+ msgcrv：可以从消息队列上接收信息，接收成功标志是消息从队列上取出，同一时间可以有多个进程同时从队列中获取消息，当队列为空时，获取消息操作会被阻塞；

Linux中，一旦一个队列被创建，除非内核重新启动或者该队列被主动删除，否则其数据都会被保留。同时消息队列空间有限，可以管理消息队列的空间。通常建议使用共享内存机制来传递长消息，而非使用消息队列。消息在永恒泰和内核态之间传递时，会有拷贝的开销。

**System V 信号量**

信号量主语用以进程间「同步」。

信号量本身能够给传递的数据量很少，一般而言仅有一个共享的整型计数器，该计数器由内核维护，对信号量的操作需要通过内核系统调用。

信号量的主要操作是两个原语：P和V。

+ P：Probeer，尝试。尝试一个操作，在信号量中通常是将计数器减1，该操作失败会将当前线程切换到阻塞状态，知道其他进程执行了V操作；
+ V：Verhoog，增加。在信号量中是将一个计数器加1。V可能会唤醒一个因P操作而陷入阻塞的进程。

P和V操作都是在信号量结构上进行，信号量结构会封装一个计数器。

信号量的一个简单设计是限制其计数器值，使其只能在0和1两个数字之间变化。

+ 当执行P操作，会视图将计数器减1，如果这个操作会将计数器减为负数，那么阻塞该进程，知道减1操作顺利完成。
+ 当执行V操作，会将计数器加1，但计算器最终的计数不能超过1。

通过这一简单设计可以支持简单的进程间同步的需求。

**System V 共享内存**

共享内存的思路是内核为通信的进程建立共享区域。一旦共享区域创建完成，内核基本不需要参与进程间的通信。通信的多昂可以直接使用共享内存区域上的数据，也可以将共享区域当成消息缓冲区。

消息队列、信号量、管道机制通常是由操作系统内核提供完整的进程间通信接口，对于它们的抽象方便了用户进程的使用，但其中涉及的数据拷贝和数据流转移等处理逻辑会影响抽象的性能。

共享内存允许一个或多个进程在其所在的虚拟地址空间中映射相同的的物理内存页，从而进行通信。

1. 内核为全局所有的共享内存维护一个全局的队列结构--内存队列，内存队列的每一项和一个IPC key绑定；
2. 每个进程可以通过同样的key找到并使用同一段共享物理内存区域（使用时会进行权限检查机制判断）；
3. 当两个进程分别对同一个共享内存建立了映射之后，内核会为它们分配两个VMA用于描述进程的一段虚拟地址空间的映射；
4. 有了VMA，内核能够从一个用户进程的虚拟地址空间找到对应的VMA，从而知道是有个共享内存区间；
5. 两个VMA的虚拟地址可以不同，但映射的是相同的物理内存；

**信号**

管道、消息队列、共享内存等机制主要关注数据传输的设计，信号特点是**单向的事件通知能力**。

信号量虽然也有通知能力，但需要进程主动主动查询计数器状态或陷入阻塞状态来等待通知。

使用信号，一个进程可以随时发送一个事件到特定的进程、线程或进程组中。并且接收时间的进程不需要阻塞等待该事件，内核会帮助其切换到对应的处理函数中响应信号事件，并且在处理完毕之后恢复之前的上下文。

信号是一种特殊的进程间通信机制，传递的消息很短，只有一个编号。在通信场景下，一个进程会为一些特定的信号编号注册处理函数。当进程接收到对应的编号，内核会自动将用户的控制流切换到对应的处理函数中。

信号的发送可以是用户态进程，也可以是内核。一个用户态进程可以通过内核提供的系统调用接口，给一个进程或线程发送特定的信号事件。在Linux中，内核会为每一个进程和线程准备一个信号事件等待队列，同一进程内的多个线程共享进程的信号事件等待队列，并拥有私有的等待队列。Linux中提供了系统调用来允许用户设置堆特定信号的阻塞状态。当一个信号被阻塞，Linux不会触发信号对应的处理函数，知道该信号被解除阻塞。

在Linux等UNIX系统设计中，信号通常在内核执行完异常、中断、系统调用等返回到用户态是被处理。处理时一般有三种方式：

+ 忽略：直接忽略对应信号；

+ 用户处理函数：用户可以通过Linux提供的系统为特定信号注册一个用户态处理函数，当内核处理对应的信号，会返回到用户态执行该函数；

+ 内核默认处理函数：通常是杀死进程或直接忽略信号。

信号处理函数执行过程中可能会触发嵌套的信号。如当前进程正在处理一个信号事件，某个其他进程发送了一个该信号事件，并且当前进程由于中断等下陷到内核，那么当前进程可能会暂停当前信号处理函数的执行，并重新切换到处理函数的开头处理新的信号。这种嵌套需要信号处理函数是**可重入**的。

可重入函数运行多个任务并发使用，不必担心数据的错误。

> Linux的Ctrl+C

Linux中在Shell使用Ctrl+C可以终止一个执行中的程序。其背后逻辑是Shell发出一个SIGINT信号，导致默认信号处理函数结束了对应的进程。

> kill

使用`kill(pid_t pid, int dig)`可以给进程号为pid的进程或进程组号为-pid的所有进程发送信号事件。

**套接字**

套接字是一种既可以用于本地，又可以跨网络使用的通信机制。应用程序可以使用相同的套接字接口来实现本地进程间通信和跨机器的网络通信。

在套接字进程间通信，客户端进程通过特定的「地址」找到要调用的服务端进程。地址在进程运行时绑定，套接字支持不同的地址类型。在进程间通信中可以使用基于IP地址和端口的组合的地址。

套接字通信可以使用不同的协议，如TCP和UDP。TCP可靠性好，协议负责数据重传、数据顺序维护等；UDP简单，重视传输性能。

> 不同IPC机制的对比

| IPC机制  | 数据抽象 | 参与者   | 方向      | 内核实现                                                   |
| -------- | -------- | -------- | --------- | ---------------------------------------------------------- |
| 管道     | 字节流   | 两个进程 | 单向      | 以FIFO缓存去管理数据。匿名管道和命名管道两种实现           |
| 消息队列 | 消息     | 多进程   | 单向/双向 | 队列组织管理。通过文件权限管理对队列的访问                 |
| 信号量   | 计数器   | 多进程   | 单向/双向 | 内核维护共享计数器，通过文件的权限管理计数器访问           |
| 共享内存 | 内存区间 | 多进程   | 单向/双向 | 内核维护共享内存区间，通过文件的权限管理共享内存访问       |
| 信号     | 时间编号 | 多进程   | 单向      | 为线程/进程维护信号等待队列，通过用户/组等权限管理信号操作 |
| 套接字   | 数据报文 | 两个进程 | 单向/双向 | 基于IP/端口和基于文件路径的寻址方式，利用网络栈管理通信    |

> 不同IPC的运用场景

| IPC机制  | 使用场景           | 使用实例                 |
| -------- | ------------------ | ------------------------ |
| 管道     | 进程通信           | pipe，fork的父子进程通信 |
| 消息队列 | 传递消息           |                          |
| 信号量   | 进程间同步         | P和V同步原语             |
| 共享内存 |                    |                          |
| 信号     | 单向事件通知       | Ctrl+C、kill             |
| 套接字   | 本地与跨网络的通信 | TCP、UDP socket          |

## 同步原语














## 操作系统调度

一个操作系统会同时管理大量的进程，这些进程的数量远远超过CPU核心数量，它们使用的内存页可能会超过可用内存的总量。为了协调多个进程对CPU和内存的使用，操作系统使用进程调度机制。

### 长/中/短期调度

进程调度机制进程状态间的切换。进程调度根据职责不同，具体分为长期、中期和短期调度。

+ 长期调度：限制系统中真正被短期调度管理的进程数量，避免短期调度开销过大；【CPU、I/O角度，间隔较长】
+ 中期调度：负责进程在就绪、运行、阻塞态之间的转换，实际做出调度决策；【CPU、I/O角度，相对频繁】
+ 短期调度：在进程占用大量内存时，负责挂起系统中被短期调度管理的进程，进而降低进程占用的内存总量。【内存角度，最为频繁】

> 计算密集型与I/O密集型

根据进程主要使用的资源，可以将进程分为计算密集型与I/O密集型。

+ 计算密集型：使用CPU进行长时间运算，性能受到处理器计算性能限制；
+ I/O密集型：等待I/O请求完成占进程的主要时间，会不间断对占用CPU以处理I/O请求。

> 挂起

中期调度在内存资源不足时，会根据某些策略选择挂起的进程。挂起的进程会被标记为对应的挂起状态，标志它不会再被调度执行。

> 长/中/短期调度的协作

操作系统进程调度的整体流程如下：

1. 批处理任务发起后，信息会被存入磁盘中的批处理队列，等待被长期调度允许进入系统；
2. **长期调度**负责从批处理队列选取下一个看调度的批处理任务，为其创建对应的进程，设置为**就绪态**，放到**运行队列**；
3. 对于交互式和实时任务，由于它们对延时要求很高，一般不会被长期调度管理，系统直接为其创建进程等操作；
4. 通过**短期调度决策**，运行队列中的进程被调度到CPU执行，此时进程为**运行态**；
5. 一个进程运行完毕，短期调度将其重新设置为就绪态，放回**运行队列**；
6. 当运行中进程需要被阻塞，会被放到**阻塞队列**，短期调度会选择其他进程进行调度；
7. 当阻塞的进程等待的事件被触发，操作系统直接将对应的线程移除阻塞独队列，并将其设置为就行，重新放入运行队列；
8. 如果系统中的内存使用量过大，会**触发换页机制**，中期调度会挂起处于就绪态/阻塞态的进程，将其设置为挂起就绪/挂起阻塞态，并放入挂起运行队列/挂起阻塞队列；
9. 处于挂起阻塞状态的进程，如果等待的事件被触发，会被置为就绪状态并被放入挂起运行队列中；
10. 当系统的内存资源不再紧张是，中期调度会激活挂起运行队列/挂起阻塞队列中的进程，将其置为就绪/阻塞状态并返回运行/阻塞队列中；
11. 当进程结束执行，会进入终止状态并最终被回收。

### 单核调度策略

到达时间：任务合适发起并处于就绪状态；

运行时间：任务从开始到结束总共花费的时间；

周转时间：

响应时间：用户发起请求到任务响应用户所需的时间。

#### 经典调度策略

**先到先得FCFS**

策略：调度时按照任务到达的先后顺序调度执行。

好处：简单直观，易于实现。

坏处：长短你认为混合的场景下对短任务不太友好；对I/O密集型任务不友好。

**最短任务优先SJF**

策略：调度时选择运行时间最短的任务执行。

好处：有利于短任务。

坏处：必须预知任务的运行时间（能判断任务的运行时间）；其表现严重依赖于任务到达时间点（调度前被感知到）。

**最短完成时间优先STCF**

策略：改进SJF策略的「迟到短任务」，是SJF的抢占式版。每次选择最短完成时间任务调度。

坏处：长任务饥饿。

**时间片轮转RR**

策略：为任务设置时间片，限定任务每次的执行时间，一个任务的时间片用完，切换到下一个任务执行。

好处：有利于交互式程序。

坏处：上下文切换开销；时间片大小难以选择；任务运行时间显示的场景下平均周转时间高（一个程序可能被切换成多个执行片执行，进而导致运行总时间被拉得很长）。

#### 优先级调度

// TODO

根据任务的目的，可以将任务划分为交互式任务和批处理任务。

+ 交互式任务：
+ 批处理任务：

| 调度策略 | 抢占式？ | 利于周转/响应 |
| -------- | -------- | ------------- |
|          |          |               |



















