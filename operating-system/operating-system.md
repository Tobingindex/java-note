# Operating-System

## 操作系统概述

### 系统职责

操作系统主要有两个职责：对硬件进行管理和抽象，为应用提供服务并进行管理。

从硬件层面，操作系统需要包含两类功能：

+ 将复杂的、具备不同功能的硬件资源纳入统一的管理
+ 负责将硬件抽象成不依赖具体硬件特性的资源，核心是「将有限的、离散的资源高效地抽象为无线的、连续的资源」

从应用层面，操作系统主要包含两类功能：

+ 提供不同层次、不同功能的接口以满足应用的需求，提供不同类型的访问控制、应用间交互
+ 操作系统负责对应用生命周期进行管理，包含应用的加载、启动、切换、调度、销毁等

### 操作系统接口

从应用角度、操作系统需要提供不同的层次接口，主要包含了系统调用接口、POSIX接口、领域引用接口。

**系统调用接口**

应用程序通过操作系统内核提供的接口向内核申请服务，如**系统调用**。系统调用是用户态应用向操作系统内核请求服务的方法。

**POSIX接口**

POSIX，Portable Operating System Interface for uniX，可移植操作系统接口。

由于每个操作系统提供的系统调用各不相同，为了同一个应用程序在不同操作系统上的可移植性，逐渐形成了一些可移植的操作系统接口标准，其中包含了POSIX。

**领域应用接口**

在POSIX或操作系统调用之上面向不同领域的领域应用接口。

### 硬件结构

现在主流计算机采用的硬件结构是冯诺依曼结构。在冯诺依曼结构中主要包括三个主要部分。

+ 中央处理器：主要负责运算和逻辑控制。
+ 存储器：负责储存程序指令和数据，以及保存程序执行的中间结果。通常包括寄存器、CPU缓存、内存等。
+ 输入输出：负责与外界打交道，从外界获取输入，并将结果向外界输出。

CPU与软件之间的桥梁是指令集架构。指令集架构主要包含了指令集、特权级、寄存器、执行模式、安全扩展、性能加速扩展等诸多方面。

**指令集**

指令集通常包含一系列不同功能的指令，用于数据搬移、计算、内存访问、过程调用等。CPU在运行操作系统或应用程序时，实际上是执行它们被编译之后包含的指令。

**特权级**

为了隔离不同功能之间造成的影响，指令集往往会提供不同的特权级。常见的特权级有用户态和内核态。对系统功能进行用户态和内核态的拆分，可以使得在用户态程序发生奔溃时，不会或很难影响到内核态程序的正常执行，从而显著提高了操作系统的安全性与可靠性。

从用户态切换到内核态的常用场景有三种：

+ 应用程序需要调用操作系统提供的系统调用【同步】
+ 应用程序会执行了一条指令，而该指令触发了异常，如应用执行访存指令时，触发了缺页异常【同步】
+ 应用程序执行过程汇总，CPU收到了一个来自外设的中断【异步】

> 同步的CPU特权级切换是由CPU正在执行的指令导致；异步的CPU特权级切换是不是由CPU运行的应用程序的指令导致

在发生特权级切换时，CPU和操作系统需要共同协作，主要流程如下：

1. CPU读取向量基地址寄存器，获得**异常向量表**的基地址
2. 根据异常原因调用操作系统设置的相应异常处理函数
3. 执行相应函数前一般会保护应用程序的上下文
4. 执行相应的异常处理函数
5. 执行完毕操作系统会恢复应用程序的上下文返回

> 为了能够在处理异常时，应用程序信息不被破坏，CPU会应用程序的执行状态进行保存，状态信息主要包含了：程序计数器、异常原因、栈指针、程序状态字寄存器、错误地址寄存器等。

**物理内存与缓存**

与CPU处理速度相比，内存的访问速度较慢。为了降低CPU访存的开销 ，现代CPU中一般引入了缓存，用于存放部分物理内存中的数据。

当CPU需要向物理内存写入数据时，可以直接在CPU缓存中；

当CPU需要从物理内存中读取数据时，可以先在CPU缓存中查找；

如果没有再到物理内存中获取，并把取回的数据放入缓存中，以便加快下次读取的速度。

**设备与中断**

输入输出设备的种类繁多、功能丰富，是冯诺依曼中的主要组成部分。输入输出设备与CPU之间的交互方式主要有以下几种方式。

+ 内存映射输入输出(MMIO)：一种常见的CPU控制和访问设备的方式，原理是把输入输出设备和物理内存放到同一个地址空间，为设备内部的内存和寄存器也分配相应的地址。
+ 轮询：CPU不通过MMIO查看是否有响应的输入，这种会浪费CPU资源
+ 中断：设备通过向CPU发出中断来打断CPU执行，使得CPU处理这个中断

## 内存管理

为了保证不同的应用程序能够**高效又安全**地共同使用物理内存资源，现代操作系统普遍使用**虚拟内存**。在引入了虚拟内存之后，应用程序是面向虚拟内存编写而不再是面向物理内存编写；应用程序运行时只能使用虚拟地址，CPU负责将虚拟地址翻译成为物理地址，操作系统负责将设置设置虚拟地址与物理地址之间的映射。

使用虚拟地址主要有以下的好处：

+ 仅将应用程序实际使用的虚拟地址映射到物理地址，**通过了内存资源的利用率**。（高效性）
+ 每个应用程序只能看到自己的虚拟地址空间，**保证了不同应用程序内存之间的隔离**。（安全性）
+ 每个应用程序的虚拟地址空间是统一的、连续的，**减低了编程的复杂性**。（透明性）

### 物理地址与虚拟地址

物理内存可以看作是大的数组，每个字节可以通过唯一的地址进行访问，这地址称为**物理地址**。在引入了虚拟地址之后，应用程序使用**虚拟地址**访问存储在物理内存中的数据和代码。虚拟地址转换为物理地址的过程，称为**地址翻译**。

在CPU中内存管理单元（MMU）负责地址翻译工作。当需要访问物理内存设备时，MMU翻译出的物理地址将会通知系统总线传到相应的物理内存设备，从而完成物理内存的读写操作。由于指令通常时保持到磁盘中，使用时需要加载到物理内存中，为了加速地址翻译，现代CPU通常会使用转址旁路缓存（TLB），嵌入到MMU。

#### 分段与分页

MMU将虚拟地址转换为物理地址的机制主要有两种：分段机制和分页机制。

**分段机制**

分段机制下，操作系统以「段」的形式来管理/分配物理内存。

应用程序的虚拟地址空间由若干不同大小的段组成，如代码段、数据段等。当时CPU访问虚拟地址空间的某个段时，MMU会先去查询段表，得到该段对应的物理内存区域。

在分段机制下，虚拟地址分为两部分：段号+段内地址

+ 段号：标识虚拟地址属于虚拟地址空间的哪一个段；
+ 段内地址：相对于该段的起始地址的偏移量。

使用分段机制操作系统可以实现物理内存资源的离散分配，但是这种方式容易导致**外部碎片**的问题。

**分页机制**

分页机制是被现代操作系统更为广泛使用的机制。

分页机制的基本思想是将应用程序的虚拟地址空间划分为连续的、等长的物理页。虚拟页和物理页固定且相等，这样可以使得操作系统方便为每个应用程序构造**页表**，即虚拟页到物理页的映射关系表。

分页机制上的虚拟地址有两部分组成：页号+页内偏移。在地址翻译时

+ MMU首先根据页号定位到该应用程序应用程序的页表中找到存储的物理页号
+ 根据物理页号对对应的物理页其实地址加上虚拟地址的**页内偏移**得到最终地址

**页号**==>页表==>物理页号==>物理页基址==>加上**页内偏移**==>最终地址

分页机制下，操作系统也能实现物理内存资源的离散分配；除此之外，分页机制按照固定的大小分配物理内存，使·得物理内存易于管理，可以**有效避免分段机制的外部碎片问题**。

#### 分页内存管理

现代操作系统广泛使用基于分页机制的虚拟内存设计实现。

在分页机制中页表是关键，主要负责记录虚拟页到物理页的映射关系。通过简单的使用一张简单的单级页表来记录映射关系，该页表将会耗费海量的空间。如对于64位虚拟地址空间，假如每页大小4KB，页表每项8字节，页表需要33554432GB，这显然是不合理的。

为了压缩页表大小，操作系统引入了**多级页表**。在使用多级页表时，一个虚拟地址被分为虚拟页号和业内偏移。其中虚拟页号被分为k个部分，每一部分虚拟页号对应该虚拟地址在该级页表中的索引。当任意一级页表某个条目为空，条目对应的下一级页表不需要存在，因此类似。因此对于多级页表允许整个表结构出现空洞，这样一来就可以节省大量的空间。

对于一个4级页表，MMU在翻译64位虚拟地址时

1. 首先根据**页表基地址寄存器**的物理地址找到0级页表，将虚拟地址的虚拟页号0作为**页表项索引**，读取第0级页表中的对应页表项；
2. 将0级页表项中存储的下一级页表页的物理地址，将虚拟地址的虚拟也号1作为页表项声音，读取第1级页表中对应页表项；
3. 以此类推，MMU将会在第3级页表页中的页表中找到对应的物理页号，结合虚拟地址的业内偏移可以获得最终地址。

```java
// 64位虚拟地址
-----------------------------------------------------------------
| 第0级虚拟页号 | 第1级虚拟页号 | 第2级虚拟页号 | 第3级虚拟页号 | 页内偏移 |
-----------------------------------------------------------------
页表基地址寄存器 + 第0级虚拟页号 ==> 第1级虚拟页物理地址
第1级虚拟页物理地址 + 第1级虚拟页号 ==> 第2级虚拟页物理地址
第2级虚拟页物理地址 + 第2级虚拟页号 ==> 第3级虚拟页物理地址
第3级虚拟页物理地址 + 第3级虚拟页号 + 页内偏移 ==> 最终物理地址
```

显然多级页表结构能显著压缩页表大小，但是会导致地址翻译的时间变长。为了减少地址翻译的访存次数，MMU引入了**转址旁路缓存**(TLB)来加速地址翻译。TLB缓存了虚拟页号到物理页号的映射关系。使用TLB时，MMU会先把虚拟页号作为键去查询TLB中的缓存项，找到则无需查询页表(TLB hit)，反之没有找到(TLB miss)。

在引入TLB，不可避免会存在数据一致性问题，即TLB与当前页表页的内容一致性问题。存在数据一致性的根本问题是，页表发生了改变，但是TLB却没有做出相应的更新。

因此处理TLB缓存一致性问题最简单的方案就是在页表切换时(应用程序切换)时主动刷新TLB。但是这种处理方式会导致每次在切换完应用程序执行时，总会发生TLB未命中的情况，进而造成性能损耗。

为此，更好的处理方案是TLB缓存项打上TAG。这种方案下，操作系统位不同的应用程序分配不同的ID用于标识身份，再将这标签ID写入到TLB的TAG位置。这样一来，TLB缓存项可以区分属于不同应用程序，在切换页表时，TLB会判断页表项是否属于当前应用程序，如果是操作系统不需要清空TLB缓存项。





















